{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb19c01a",
   "metadata": {},
   "source": [
    "### Introduction to Data Ingestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7841a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36524bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Up Complete!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter, \n",
    "    CharacterTextSplitter, \n",
    "    TokenTextSplitter\n",
    ")\n",
    "print(\"Set Up Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefaa2d8",
   "metadata": {},
   "source": [
    "### Uderstanding Document Structure in Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250dee8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Structure\n",
      "Content:This is the main text content that will be embedded and searched.\n",
      "Metadata:{'source': 'example.txt', 'page': 1, 'author': 'Tejaswi Shetty', 'date_created': '2025-08-14', 'custom_field': 'any_value'}\n"
     ]
    }
   ],
   "source": [
    "#create a simple document\n",
    "\n",
    "doc = Document(\n",
    "    page_content=\"This is the main text content that will be embedded and searched.\", \n",
    "    metadata = {\n",
    "        \"source\":\"example.txt\", \n",
    "        \"page\":1,\n",
    "        \"author\":\"Tejaswi Shetty\",\n",
    "        'date_created':\"2025-08-14\",\n",
    "        \"custom_field\":\"any_value\"\n",
    "    }\n",
    ")\n",
    "print(\"Document Structure\")\n",
    "\n",
    "print(f\"Content:{doc.page_content}\")\n",
    "print(f\"Metadata:{doc.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bc83cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.documents.base.Document"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e95dc7",
   "metadata": {},
   "source": [
    "### Text file(.txt) - The simple Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1a8a752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a simple text file\n",
    "\n",
    "import os\n",
    "os.makedirs(\"data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d86fb7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample file created successfully!\n"
     ]
    }
   ],
   "source": [
    "sample_texts = {\n",
    "    \"data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "\"data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "for file_path, content in sample_texts.items():\n",
    "    with open(file_path,'w', encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Sample file created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed9022",
   "metadata": {},
   "source": [
    "### TextLoader -  Read Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d64ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n",
      "Loaded 1 document\n",
      "Content preview:Python Programming Introduction\n",
      "\n",
      "Python is a high-level, interpreted programming language known for ...\n",
      "Metadata: {'source': 'data/text_files/python_intro.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "print(type(documents))\n",
    "print(documents)\n",
    "\n",
    "print(f\"Loaded {len(documents)} document\")\n",
    "print(f\"Content preview:{documents[0].page_content[:100]}...\")\n",
    "print(f\"Metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7f5f20",
   "metadata": {},
   "source": [
    "#### DirectoryLoader - multiple text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f11b0c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 180.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 documents\n",
      "\n",
      " Documents 1\n",
      " Source: data\\text_files\\machine_learning.txt\n",
      " Length: 569 characters\n",
      "\n",
      " Documents 2\n",
      " Source: data\\text_files\\python_intro.txt\n",
      " Length: 489 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "### load all the text files from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"data/text_files\", \n",
    "    glob = \"**/*.txt\", #Pattern to match files\n",
    "    loader_cls = TextLoader, ### loader class to use\n",
    "    loader_kwargs = {'encoding':'utf-8'},\n",
    "    show_progress = True\n",
    ")\n",
    "\n",
    "documents = dir_loader.load()\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"\\n Documents {i+1}\")\n",
    "    print(f\" Source: {doc.metadata['source']}\")\n",
    "    print(f\" Length: {len(doc.page_content)} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60c8edad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "that can access data and use it to learn for themselves.\n",
      "\n",
      "Types of Machine Learning:\n",
      "1. Supervised Learning: Learning with labeled data\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
      "3. Reinforcement Learning: Learning through rewards and penalties\n",
      "\n",
      "Applications include image recognition, speech processing, and recommendation systems\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter, \n",
    "    CharacterTextSplitter, \n",
    "    TokenTextSplitter)\n",
    "print(documents[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0345b221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character text splitter\n",
      "Created 4 chunks\n",
      "First chunk: Machine Learning Basics\n",
      "Machine learning is a subset of artificial intelligence that enables systems...\n"
     ]
    }
   ],
   "source": [
    "### Method 1 - Character Text Splitter\n",
    "\n",
    "text = documents[0].page_content\n",
    "\n",
    "print(\"Character text splitter\")\n",
    "\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", \n",
    "    chunk_size = 200, \n",
    "    chunk_overlap = 20, \n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "print(f\"Created {len(char_chunks)} chunks\")\n",
    "print(f\"First chunk: {char_chunks[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20588fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Basics\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "-----\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "that can access data and use it to learn for themselves.\n",
      "Types of Machine Learning:\n",
      "-----\n",
      "1. Supervised Learning: Learning with labeled data\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
      "3. Reinforcement Learning: Learning through rewards and penalties\n"
     ]
    }
   ],
   "source": [
    "print(char_chunks[0])\n",
    "print(\"-----\")\n",
    "print(char_chunks[1])\n",
    "print(\"-----\")\n",
    "print(char_chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bd55ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recursive Character text splitter\n",
      "Created 6 chunks\n",
      "First chunk: Machine Learning Basics...\n"
     ]
    }
   ],
   "source": [
    "### Method 2 - Recursive Character Text Splitter\n",
    "text = documents[0].page_content\n",
    "\n",
    "print(\"Recursive Character text splitter\")\n",
    "\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  \n",
    "    chunk_size = 200, \n",
    "    chunk_overlap = 20, \n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "print(f\"Created {len(recursive_chunks)} chunks\")\n",
    "print(f\"First chunk: {recursive_chunks[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09bee449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning Basics\n",
      "-----\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "-----\n",
      "that can access data and use it to learn for themselves.\n"
     ]
    }
   ],
   "source": [
    "print(recursive_chunks[0])\n",
    "print(\"-----\")\n",
    "print(recursive_chunks[1])\n",
    "print(\"-----\")\n",
    "print(recursive_chunks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "235cb789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Simple text example - 4 chunks\n",
      "\n",
      "Chunks 1: 'This is sentence one and it is quite long. This is sentence two and it is also\n",
      "Chunks 2: 'two and it is also quite long. This is sentence three which is even longer than\n",
      "\n",
      "Chunks 2: 'two and it is also quite long. This is sentence three which is even longer than\n",
      "Chunks 3: 'is even longer than the others. This is sentence four. This is sentence five.\n",
      "\n",
      "Chunks 3: 'is even longer than the others. This is sentence four. This is sentence five.\n",
      "Chunks 4: 'is sentence five. This is sentence six.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Create text without natural break points \n",
    "\n",
    "simple_text = simple_text = \"This is sentence one and it is quite long. This is sentence two and it is also quite long. This is sentence three which is even longer than the others. This is sentence four. This is sentence five. This is sentence six.\"\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators = [\" \"], \n",
    "    chunk_size = 80, \n",
    "    chunk_overlap = 20, \n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(simple_text)\n",
    "\n",
    "print(f\"\\n Simple text example - {len(chunks)} chunks\\n\")\n",
    "\n",
    "for i in range(len(chunks)-1):\n",
    "    print(f\"Chunks {i+1}: '{chunks[i]}\")\n",
    "    print(f\"Chunks {i+2}: '{chunks[i+1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5c50dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n TOKEN TEXT SPLITTER\n",
      "Created 3 chunks\n",
      "First chunk: Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables system ..\n"
     ]
    }
   ],
   "source": [
    "#method 3: Token-based splitting\n",
    "\n",
    "print(\"/n TOKEN TEXT SPLITTER\")\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size = 50, \n",
    "    chunk_overlap = 10\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "print(f\"Created {len(token_chunks)} chunks\")\n",
    "print(f\"First chunk: {token_chunks[0][:100]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe34e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultimate_rag_bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
